{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988ab31e",
   "metadata": {},
   "source": [
    "Inizializzazione Rete Neurale e prima run in assenza di algoritmi evolutivi, usando parametri casuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Fa4H/computational_intelligence/refs/heads/main/brain_tumor.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X, y = df.iloc[:, 2:].copy(), df.iloc[:, 1].copy()\n",
    "\n",
    "X_tr_val, X_test, y_tr_val, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr_val, y_tr_val, test_size = 0.2, random_state = 1, stratify = y_tr_val)\n",
    "\n",
    "vals, counts = np.unique(y_val, return_counts=True)\n",
    "#print(vals)    # → valori unici\n",
    "#print(counts)\n",
    "nums_0 = counts[0]\n",
    "nums_1 = counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_val_std = sc.transform(X_val)\n",
    "X_test_std = sc.transform(X_test)\n",
    "print(X_train_std[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a800945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=100, activation=\"logistic\", alpha=0.1, solver=\"sgd\", learning_rate=\"constant\", learning_rate_init=0.001, random_state=1, shuffle=True, tol=0.0001, verbose=True, warm_start=False)\n",
    "\n",
    "mlp.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc13040",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = mlp.predict(X_val_std)\n",
    "c = confusion_matrix(pred_val, y_val)\n",
    "print(classification_report(pred_val, y_val, zero_division=0))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99274f",
   "metadata": {},
   "source": [
    "Definizione algoritmo evolutivo genetico e implementazione nella rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98985a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layers_encoding():\n",
    "  numlays = np.random.randint(1, 3)\n",
    "  a = [np.random.randint(1, 100) for i in range(numlays)]\n",
    "  return a\n",
    "\n",
    "def max_iter_encoding():\n",
    "  return np.random.randint(1, 500)\n",
    "\n",
    "def activation_encoding():\n",
    "  return np.random.randint(0, 3)\n",
    "\n",
    "def activation_decoding(gene_value):\n",
    "    if not hasattr(activation_decoding, \"_phenotypes\"):\n",
    "        activation_decoding._phenotypes = (\"relu\", \"tanh\", \"logistic\", \"identity\")  # solo alla prima chiamata\n",
    "    return activation_decoding._phenotypes[gene_value] # riusa il dizionario nelle chiamate successive\n",
    "\n",
    "def alpha_encoding(min_alpha = 10**-4, max_alpha = 10**0, exp_step = 0.01):\n",
    "    \"\"\"\n",
    "    encoding: alpha appartenente a range di Reali (phenotype space) --->  numero di step appartenente a sottoinsieme di Interi (genotype space)\n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    La funzione di encoding genera un numero naturale tra 0 ed un numero intero massimo che è determinato\n",
    "    dal numero totale ammissibile di valori distinti discretizzati di alpha, tenendo in conto\n",
    "    la restrizione data dal range [min_alpha, max_alpha] e exp_step.\n",
    "    Considerando la discretizzazione lineare nella potenza di 10, questo intero corrisponde semanticamente al numero di exp_step da aggiungere\n",
    "    a min_exp per ottenere l'esponente da dare a 10 per ottenere alpha.\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcolo di esponente minimo, massimo e numero di step in questo range\n",
    "    min_exp = np.log10(min_alpha)\n",
    "    max_exp = np.log10(max_alpha)\n",
    "    num_step = int((max_exp - min_exp) / exp_step)\n",
    "    # Estraggo il valore del gene: un valore intero randomico di step da fare\n",
    "    gene_value = random.randint(0, num_step)\n",
    "\n",
    "    return gene_value\n",
    "\n",
    "def alpha_decoding(gene_value, min_alpha = 10**-4, max_alpha = 10**0, exp_step = 0.01):\n",
    "    \"\"\"\n",
    "    decoding: numero di step appartenente a sottoinsieme di Interi (genotype space) ---> alpha appartenente a range di Reali (phenotype space)\n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    La funzione di decoding assume il valore intero del gene (gene_value) e lo associa semanticamente al numero\n",
    "    di exp_step che bisogna aggiungere al min_exp per ottenere l'esponente da dare a 10 per ottenere il corrispondente alpha.\n",
    "    alpha = 10**(min_exp + gene_value*exp_step) -- lineare nell'esponente --\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcolo di esponente minimo, massimo e numero di step in questo range\n",
    "    min_exp = np.log10(min_alpha)\n",
    "    max_exp = np.log10(max_alpha)\n",
    "    num_step = int((max_exp - min_exp) / exp_step)\n",
    "    # Calcolo l'esponente da dare a 10 partendo dal valore minimo e aggiungendo ad esso un numero \"gene_value\" di exp_step (è lineare nell'esponente)\n",
    "    esp = min_exp + gene_value*exp_step\n",
    "    # Calcolo alpha\n",
    "    alpha = 10**esp\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def learning_rate_init_encoding(min_lri = 10**-4,  max_lri = 10**-2,  exp_step = 0.01):\n",
    "    \"\"\"\n",
    "    encoding: lri appartenente a range di Reali (phenotype space) --->  numero di step appartenente a sottoinsieme di Interi (genotype space)\n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    La funzione di encoding genera un numero naturale tra 0 ed un numero intero massimo che è determinato\n",
    "    dal numero totale ammissibile di valori distinti discretizzati di learning_rate_init, tenendo in conto\n",
    "    la restrizione data dal range [min_lri, max_lri] e exp_step.\n",
    "    Considerando la discretizzazione lineare nella potenza di 10, questo intero corrisponde semanticamente al numero di exp_step da aggiungere\n",
    "    a min_exp per ottenere l'esponente da dare a 10 per ottenere learning_rate_init.\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcolo di esponente minimo, massimo e numero di step in questo range\n",
    "    min_exp = np.log10(min_lri)\n",
    "    max_exp = np.log10(max_lri)\n",
    "    num_step = int((max_exp - min_exp) / exp_step)\n",
    "    # Estraggo il valore del gene: un valore intero randomico di step da fare\n",
    "    gene_value = random.randint(0, num_step)\n",
    "\n",
    "    return gene_value\n",
    "\n",
    "def learning_rate_init_decoding(gene_value, min_lri = 10**-4,  max_lri = 10**-2,  exp_step = 0.01):\n",
    "    \"\"\"\n",
    "    decoding: numero di step appartenente a sottoinsieme di Interi (genotype space) ---> lri appartenente a range di Reali (phenotype space)\n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    La funzione di decoding assume il valore intero del gene (gene_value) e lo associa semanticamente al numero\n",
    "    di exp_step che bisogna aggiungere al min_exp per ottenere l'esponente da dare a 10 per ottenere il corrispondente learning_rate_init.\n",
    "    lri = 10**(min_exp + gene_value*exp_step) -- lineare nell'esponente --\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcolo di esponente minimo, massimo e numero di step in questo range\n",
    "    min_exp = np.log10(min_lri)\n",
    "    max_exp = np.log10(max_lri)\n",
    "    num_step = int((max_exp - min_exp) / exp_step)\n",
    "    # Calcolo l'esponente da dare a 10 partendo dal valore minimo e aggiungendo ad esso un numero \"gene_value\" di exp_step (è lineare nell'esponente)\n",
    "    esp = min_exp + gene_value*exp_step\n",
    "    # Calcolo lri\n",
    "    lri = 10**esp\n",
    "\n",
    "    return lri\n",
    "\n",
    "def tol_encoding(min_tol = 10**-8,  max_tol = 10**-4,  exp_step = 0.01):\n",
    "    \"\"\"\n",
    "    encoding: tol appartenente a range di Reali (phenotype space) --->  numero di step appartenente a sottoinsieme di Interi (genotype space)\n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    La funzione di encoding genera un numero naturale tra 0 ed un numero intero massimo che è determinato\n",
    "    dal numero totale ammissibile di valori distinti discretizzati di tol, tenendo in conto\n",
    "    la restrizione data dal range [min_tol, max_tol] e exp_step.\n",
    "    Considerando la discretizzazione lineare nella potenza di 10, questo intero corrisponde semanticamente al numero di exp_step da aggiungere\n",
    "    a min_exp per ottenere l'esponente da dare a 10 per ottenere tol.\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcolo di esponente minimo, massimo e numero di step in questo range\n",
    "    min_exp = np.log10(min_tol)\n",
    "    max_exp = np.log10(max_tol)\n",
    "    num_step = int((max_exp - min_exp) / exp_step)\n",
    "    # Estraggo il valore del gene: un valore intero randomico di step da fare\n",
    "    gene_value = random.randint(0, num_step)\n",
    "\n",
    "    return gene_value\n",
    "\n",
    "def tol_decoding(gene_value, min_tol = 10**-8,  max_tol = 10**-4,  exp_step = 0.01):\n",
    "    \"\"\"\n",
    "    decoding: numero di step appartenente a sottoinsieme di Interi (genotype space) ---> tol appartenente a range di Reali (phenotype space)\n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    La funzione di decoding assume il valore intero del gene (gene_value) e lo associa semanticamente al numero\n",
    "    di exp_step che bisogna aggiungere al min_exp per ottenere l'esponente da dare a 10 per ottenere il corrispondente tol.\n",
    "    tol = 10**(min_exp + gene_value*exp_step) -- lineare nell'esponente --\n",
    "\n",
    "    \"\"\"\n",
    "    # Calcolo di esponente minimo, massimo e numero di step in questo range\n",
    "    min_exp = np.log10(min_tol)\n",
    "    max_exp = np.log10(max_tol)\n",
    "    num_step = int((max_exp - min_exp) / exp_step)\n",
    "    # Calcolo l'esponente da dare a 10 partendo dal valore minimo e aggiungendo ad esso un numero \"gene_value\" di exp_step (è lineare nell'esponente)\n",
    "    esp = min_exp + gene_value*exp_step\n",
    "    # Calcolo lri\n",
    "    tol = 10**esp\n",
    "\n",
    "    return tol\n",
    "\n",
    "encoding = [hidden_layers_encoding, max_iter_encoding, activation_encoding, alpha_encoding, learning_rate_init_encoding, tol_encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_based(offspring, pop):\n",
    "    return offspring\n",
    "def fitness_based(offspring, pop):\n",
    "    return tools.selBest(offspring + pop, k=len(pop))\n",
    "\n",
    "def new_pop_decoding(gene_value):\n",
    "    if not hasattr(new_pop_decoding, \"_phenotypes\"):\n",
    "        new_pop_decoding._phenotypes = (age_based, fitness_based)  # solo alla prima chiamata\n",
    "    return new_pop_decoding._phenotypes[gene_value] # riusa il dizionario nelle chiamate successive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_problem():\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights = (1.0,))\n",
    "    creator.create(\"Individual\", list, fitness = creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", tools.initCycle, creator.Individual, encoding, n = 1)\n",
    "\n",
    "    def evalFitness(individual):\n",
    "        # decoding (inverse representation to create the corresponding phenotype)\n",
    "        hidden_layers = individual[0]\n",
    "        max_iter = individual[1]\n",
    "        activation = activation_decoding(individual[2])\n",
    "        alpha = alpha_decoding(individual[3])\n",
    "        learning_rate_init = learning_rate_init_decoding(individual[4])\n",
    "        tol = tol_decoding(individual[5])\n",
    "        # costruzione e apprendimento della NN\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layers, activation=activation, alpha=alpha, max_iter=max_iter, learning_rate_init=learning_rate_init, tol=tol)\n",
    "        mlp.fit(X_train_std, y_train)\n",
    "        # validazione\n",
    "        pred_val = mlp.predict(X_val_std)\n",
    "        # quality measure in the phenotype space\n",
    "        report = classification_report(pred_val, y_val, zero_division=0,output_dict=True)\n",
    "        f1_class0 = report['0']['f1-score']\n",
    "        f1_class1 = report['1']['f1-score']\n",
    "        f1_weighted = (f1_class0*nums_0 + f1_class1*nums_1)/(nums_0 + nums_1)\n",
    "        return f1_weighted,\n",
    "\n",
    "    toolbox.register(\"evaluate\", evalFitness)\n",
    "\n",
    "    return toolbox\n",
    "\n",
    "toolbox_problema = setup_problem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filtra il ConvergenceWarning di scikit-learn\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA(toolbox = toolbox_problema , popSize = 10, CXPB = 0.7, MUTPB = 0.3, indpbMUT = 0.1 , maxEvals = 100, maxGens = None, cxFUNC = tools.cxTwoPoint, mutFUNC = mutCustom1, mut_params=None, selFUNC = tools.selTournament, new_pop = age_based, tournsize = 3, verbose = False):\n",
    "\n",
    "    # Registriamo altri oggetti caratteristici dell'algoritmo e non del problema\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", cxFUNC)\n",
    "    toolbox.register(\"mutate\", mutFUNC, indpb = indpbMUT)\n",
    "    toolbox.register(\"parent_select\", selFUNC, tournsize = tournsize)\n",
    "    toolbox.register(\"next_gen\", new_pop)\n",
    "\n",
    "\n",
    "    # definizione statistiche\n",
    "    stats = tools.Statistics(key = lambda ind: ind.fitness.values)\n",
    "    def Mean(L):\n",
    "        return round(np.mean(L), 2)\n",
    "    def Std(L):\n",
    "        return round(np.std(L), 2)\n",
    "    def Min(L):\n",
    "        return round(np.min(L), 2)\n",
    "    def Max(L):\n",
    "        return round(np.max(L), 2)\n",
    "\n",
    "    stats.register(\"avg\", Mean)\n",
    "    stats.register(\"std\", Std)\n",
    "    stats.register(\"min\", Min)\n",
    "    stats.register(\"max\", Max)\n",
    "\n",
    "    halloffame = tools.HallOfFame(1)\n",
    "\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = [\"gen\", \"nevals\"] + stats.fields\n",
    "\n",
    "    # creazione della popolazione\n",
    "    pop = toolbox.population(popSize)\n",
    "\n",
    "    invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "    fitness = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitness):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "\n",
    "    halloffame.update(pop)\n",
    "    rec = stats.compile(pop)\n",
    "    logbook.record(gen = 0, nevals = len(invalid_ind) , **rec)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "    g = 0\n",
    "    while np.sum(logbook.select(\"nevals\")) < maxEvals:\n",
    "        g += 1\n",
    "        # Select the next generation of parents. These are only links to the individuals of pop. Then, need to deep clone them to avoid changes in place\n",
    "        sel_offspring = toolbox.parent_select(pop, len(pop)) # selects n(=len(pop)) individuals from n with duplicates allowed\n",
    "        # Clone the selected individuals\n",
    "        offspring = list(map(toolbox.clone, sel_offspring))\n",
    "        # Apply crossover on the offspring\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]): # Parents early selected will be the childrens because toolbox.mate changes them in place\n",
    "            if random.random() < CXPB:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "        # Apply mutation on the offspring\n",
    "        for mutant in offspring:\n",
    "            if random.random() < MUTPB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the halloffame with the generated individuals\n",
    "        halloffame.update(offspring)\n",
    "        # The population is entirely replaced by the offspring (age-based selection) or chosen from best fitness individuals\n",
    "        pop[:] = toolbox.next_gen(offspring, pop)\n",
    "        # Append the current generation statistics to the logbook\n",
    "        rec = stats.compile(pop)\n",
    "        logbook.record(gen = g, nevals = len(invalid_ind), **rec)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "    return pop, logbook, halloffame[0],  halloffame[0].fitness.values[0]\n",
    "\n",
    "pops, logb, hof, hoffit = GA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880feae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hof, hoffit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il GA ha i seguenti geni:\n",
    "- popSize: range [5, 20]\n",
    "- CXPB: [0.1, 0.9]\n",
    "- MUTPB: [0.05, 0.5]\n",
    "- indpbMUT: [0.05, 0.5]\n",
    "- maxEvals: [popSize, 10*popSize]\n",
    "- cxFUNC: [cxOnePoint, cxTwoPoint, cxUniform] se si usa cxUniform serve l'attributo indpbCX\n",
    "- indpbCX: [0.2, 0.8] \n",
    "- mutFUNC: [mutReinit, mutGaussianRound, mutDecay]\n",
    "- selFunc: [selTournament, selRoulette, selRandom, selBest] se si usa selTournament serve l'attributo tournsize\n",
    "- tournsize: tourn = [int(0.3*popSize), int(0.5*popSize)]   con restrizione toursize = max(3, tourn)   \n",
    "- new_pop: [age_based, fitness_based]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNZIONI DI ENCODING E DECODING\n",
    "\n",
    "def popSize_encoding():\n",
    "    popsize = random.randint(5, 20)\n",
    "    return popsize\n",
    "\n",
    "def CXPB_encoding(min_CXPB = 0.1, max_CXPB = 0.9, step = 0.1):\n",
    "    num_step = int((max_CXPB - min_CXPB) / step)\n",
    "    gene_value = random.randint(0, num_step)\n",
    "    return gene_value\n",
    "\n",
    "def CXPB_decoding(gene_value, min_CXPB = 0.1, max_CXPB = 0.9, step = 0.1):\n",
    "    cxpb = min_CXPB + gene_value*step\n",
    "    return cxpb\n",
    "\n",
    "def MUTPB_encoding(min_MUTPB = 0.05, max_MUTPB = 0.5, step = 0.01):\n",
    "    num_step = int((max_MUTPB - min_MUTPB) / step)\n",
    "    gene_value = random.randint(0, num_step)\n",
    "    return gene_value\n",
    "\n",
    "def MUTPB_decoding(gene_value, min_MUTPB = 0.05, max_MUTPB = 0.5, step = 0.01):\n",
    "    mutpb = min_MUTPB + gene_value*step\n",
    "    return mutpb\n",
    "\n",
    "def indpbMUT_encoding(min_indpbMUT = 0.05, max_indpbMUT = 0.5, step = 0.05):\n",
    "    num_step = int((max_indpbMUT - min_indpbMUT) / step)\n",
    "    gene_value = random.randint(0, num_step)\n",
    "    return gene_value\n",
    "\n",
    "def indpbMUT_decoding(gene_value, min_indpbMUT = 0.05, max_indpbMUT = 0.5, step = 0.05):\n",
    "    indpbMUT = min_indpbMUT + gene_value*step\n",
    "    return indpbMUT\n",
    "popSize = popSize_encoding()\n",
    "\n",
    "def maxEvals_encoding(min_maxEvals = popSize, max_maxEvals = 10*popSize): # DA DOVE PRENDO POPSIZE NELLA CREAZIONE DEL GENE?\n",
    "    maxEvals = random.randint(min_maxEvals, max_maxEvals)\n",
    "    return maxEvals\n",
    "\n",
    "def eval():\n",
    "    popsize = decoding(ind[0])\n",
    "    mutpb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    cxFunc = individual[3]\n",
    "    indpbcx = None\n",
    "    if cxFunc == \"cxUniform\":\n",
    "        indpbcx = 0.5\n",
    "    \n",
    "\n",
    "    GA(cxfunc = cxFunc, indpbcx = indpcx)\n",
    "def eval():\n",
    "    cxFunc = individual[3]\n",
    "    indpbcx = individual[4] \n",
    "    if cxFunc != \"cxUniform\":\n",
    "        indpbcx = None\n",
    "\n",
    "encoding = [hidden_layers_encoding, max_iter_encoding, activation_encoding, alpha_encoding, learning_rate_init_encoding, tol_encoding]\n",
    "\n",
    "def mutCustom1(individual, indpb):\n",
    "    for i in encoding:\n",
    "        if random.random() < indpb:\n",
    "            individual[i] = encoding[i]()\n",
    "    return individual\n",
    "\n",
    "def mutGaussianRound(individual, indpb):\n",
    "    if random.random() < indpb:\n",
    "        # Applica mutazione gaussiana al primo gene (numero di neuroni per strato)\n",
    "        for i in range(len(individual[0])):\n",
    "            mutated_value = individual[0][i] + random.gauss(0, (bound[1]-bound[0])*10/100)\n",
    "            # Arrotonda al numero intero più vicino\n",
    "            mutated_value = int(round(mutated_value))\n",
    "            # Clampa il valore entro i limiti validi\n",
    "            mutated_value = max(bound[0], min(mutated_value, bound[1]))\n",
    "            individual[0][i] = mutated_value\n",
    "    for i in range(1, len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            # Applica rumore gaussiano\n",
    "            mutated_value = individual[i] + random.gauss(0, (bound[i+1]-bound[i])*10/100)\n",
    "            # Arrotonda al numero intero più vicino\n",
    "            mutated_value = int(round(mutated_value))\n",
    "            # Clampa il valore entro i limiti validi per quel gene\n",
    "            mutated_value = max(bound[i], min(mutated_value, bound[i+1]))\n",
    "            individual[i] = mutated_value\n",
    "    return individual\n",
    "\n",
    "def mutRandomDecay(individual, current_evals, maxEvals, indpb):\n",
    "    \"\"\"\n",
    "        Mutazione che decresce nel tempo.\n",
    "    \"\"\"\n",
    "    # Calcola il fattore di decrescita basato sul numero di valutazioni correnti\n",
    "    decay_factor = 1 - current_evals / maxEvals\n",
    "\n",
    "    if random.random() < indpb:\n",
    "        # Applica mutazione gaussiana al primo gene (numero di neuroni per strato)\n",
    "        for i in range(len(individual[0])):\n",
    "            # Applica la mutazione decrescente\n",
    "            mut = random.random(-1, 1)*individual[0][i]*decay_factor + individual[0][i]\n",
    "            # Clampa il valore entro i limiti validi per quel gene\n",
    "            individual[0][i] = max(bound(0), min(mut, bound(1)))\n",
    "    for i in range(1, len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            # Applica la mutazione decrescente\n",
    "            mut = random.random(-1, 1)*individual[i]*decay_factor + individual[i]\n",
    "            # Clampa il valore entro i limiti validi per quel gene\n",
    "            individual[i] = max(bound(i), min(mut, bound(i+1)))\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxFuncde = decoding(individual[3]) \n",
    "indpbcx = individual[4]\n",
    "toursizede = individual[5]\n",
    "GA(cxFunc = cxFuncde, tournsize = toursizede)\n",
    "    if cxFunc == tools.cxUniform:\n",
    "        toolbox.register(\"mate\", cxFunc, indpb=indpbcx )\n",
    "    else:\n",
    "        toolbox.register(\"mate\", cxFunc)\n",
    "\n",
    "    if selFunc == tools.selTournament:\n",
    "        toolbox.register(\"parent_select\", tools.selTournament, tournsize = tournsize, k = popSize)\n",
    "    else:\n",
    "        toolbox.register(\"parent_select\", selFunc, k = popSize)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
